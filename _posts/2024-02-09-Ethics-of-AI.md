---
layout: post
title:  "The Dangers of AI"
date: 2024-02-09
description: A look into the potential issues with using AI 
image: "/assets/img/AI.jpg"
display_image: false  # change this to true to display the image below the banner 
---
<p class="intro"><span class="dropcap">T</span>his post will dive into the dangers of using AI in data science. We will look at a brief history of AI, potential issues in its deployment, and why that is pertinent to data science.</p>


### A History of AI

AI was birthed in 1950, when British mathematician, Alan Turing, created a test of machine intelligence. If you've seen the film "The Imitation Game" then you are familiar with this story. Turing, however, was greatly weighed down by the technology of his time. Computers needed to greatly develop before there could be any hope of true artifical intelligence.

The following decades would see a huge level of advancement in artifical intelligence. Though rudimentary compared to today's machines, the public learned from these creations what the future could look like.

<img src="{{site.url}}/{{site.baseurl}}/assets/img/alan_turing.jpg" alt="" style="width:300px;"/>
*Alan Turing working on The Imitation Game*

Starting in the early 2000s the public was given more and more access to AI. Windows released a speech recognition software, the first Roomba was unveiled, social media companies began using AI as part of their algorithms, and companies like Apple and Google rolled out their virtual assistants. Most recently, of course, has been the invention of ChatGPT and Dall-E. For a more complete explanation of AI's past, read the following [history from Tableau](https://www.tableau.com/data-insights/ai/history#:~:text=Birth%20of%20AI%3A%201950%2D1956&text=into%20popular%20use.-,Dates%20of%20note%3A,ever%20learn%20the%20game%20independently.).

While these inventions undoutedbly contributed to making life easier in many ways, there are things we need to be very careful about with AI.


### Potential Dangers of AI

The most important thing to remember is that, although AI is built to gather data and produce output completely on its own, it still was built by an imperfect human. Human tendencies and biases go into every machine, algorithm, and AI, no matter how objective it may seem at first.

These are some of the potential dangers of AI:
* Discrimination
* Harmful feedback loops
* Privacy violations
* Lack of transparency
* Security vulnerabilities
* Job displacement

The biggest problem with Big Data is that AI is often forced to use proxy data to make decisions in the name of fairness, ease, and affordability. Companies want to make things as quick and cheap as possible, so most of them turn to artifical intelligence. Whether it be finding people at which to target their ads, deciding the next promotion, or firing the next employee, AI can be unethically used to unfairly impact people that just happened to fail in one of the proxy areas the AI regarded as important.


### The Connection to Data Science